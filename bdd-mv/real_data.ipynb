{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c338d2",
   "metadata": {},
   "source": [
    "# Tests using real data benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b864c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## External modules.\n",
    "from contextlib import ExitStack\n",
    "from copy import deepcopy\n",
    "from json import load as json_load\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "## Internal modules.\n",
    "from mml.utils import makedir_safe\n",
    "from mml.utils.mest import scale_madmed\n",
    "from setup_data import get_data\n",
    "from setup_losses import get_loss\n",
    "from setup_models import get_model\n",
    "from setup_results import img_dir, results_dir, my_fontsize, my_ext, export_legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the risk classes we want to consider.\n",
    "riskclasses = [\"erm\", \"mvHuber\", \"cvar\", \"dro\"]\n",
    "\n",
    "risk_names = {\"erm\": \"Vanilla ERM\",\n",
    "              \"mvHuber\": \"Modified Sun-Huber\",\n",
    "              \"cvar\": \"CVaR risk\",\n",
    "              \"entropic\": \"Tilted risk\",\n",
    "              \"dro\": r\"$\\chi^{2}$-DRO risk\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92929bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose the dataset we want to consider.\n",
    "dataset = \"adult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216de21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose a risk class, model, and learning algorithm combination.\n",
    "loss_base = \"logistic\" # specify base loss name.\n",
    "model = \"linreg_multi\" # specify model name\n",
    "algo = \"SGD_Ave\" # specify algo name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directory setup.\n",
    "makedir_safe(img_dir)\n",
    "toread_dir = os.path.join(results_dir, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dadc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the evaluation metrics to look at (for selecting \"best settings\").\n",
    "ltype = \"base\" #\"obj\"\n",
    "etypes = [\"train\", \"val\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94953e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify which epoch to use.\n",
    "epoch_touse = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the statistic index to use (for selection).\n",
    "stat_idx = 0 # mean is 0, median is 1, std is 2.\n",
    "\n",
    "## Specify the statistic index to use (for visualization).\n",
    "stat_idx_vis = 0 # mean is 0, median is 1, std is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28aca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linestyles for discriminating train/val/test.\n",
    "linestyles = {\"train\": \"dotted\",\n",
    "              \"val\": \"dashed\",\n",
    "              \"test\": \"solid\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3994b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extras naming etc.\n",
    "extras_keys = {\"erm\": [],\n",
    "               \"mvHuber\": [\"alpha_strat\"], #[\"beta\"],\n",
    "               \"cvar\": [\"prob\"],\n",
    "               \"dro\": [\"atilde\"]}\n",
    "\n",
    "extras_symbols = {\"erm\": [],\n",
    "                  \"mvHuber\": [r\"$\\alpha strat$\"], #[r\"$\\beta$\"],\n",
    "                  \"cvar\": [r\"$\\beta$\"],\n",
    "                  \"dro\": [r\"$\\widetilde{a}$\"]}\n",
    "\n",
    "def parse_extras(extras, risk_name):\n",
    "    if risk_name in [\"erm\", \"meanvar\"]:\n",
    "        return None\n",
    "    elif risk_name == \"mvHuber\":\n",
    "        #return r\"$\\beta=${}\".format(extras[\"beta\"])\n",
    "        return r\"$\\alpha$ strat {}\".format(extras[\"alpha_strat\"])\n",
    "    elif risk_name == \"cvar\":\n",
    "        return r\"$\\beta=${}\".format(extras[\"prob\"])\n",
    "    elif risk_name == \"dro\":\n",
    "        return r\"$\\widetilde a=${}\".format(extras[\"atilde\"])\n",
    "    else:\n",
    "        raise ValueError(\"Please pass a valid risk name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e661a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary for storing the best/representative settings for each risk class.\n",
    "best_settings = {riskclass: [] for riskclass in riskclasses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beff65e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Gathering, processing, and visualization all handled in one big loop.\n",
    "\n",
    "for riskclass in riskclasses:\n",
    "    \n",
    "    ## Most of the filename is already specified.\n",
    "    mth_base = riskclass+\"_\"+loss_base+\"_\"+model+\"_\"+algo\n",
    "    \n",
    "    ## Initialize a dict of results.\n",
    "    results_dict = {}\n",
    "    \n",
    "    ## Gather the relevant hyperparameter indices to be parsed.\n",
    "    all_files = os.listdir(toread_dir)\n",
    "    r_values = []\n",
    "    s_values = []\n",
    "    for filename in all_files:\n",
    "        _mth, extension = filename.split(\".\")\n",
    "        if extension == \"json\":\n",
    "            task, _mth_base = _mth.split(\"-\")\n",
    "            if mth_base == _mth_base:\n",
    "                s_value, r_value = task.split(\"s\")[1].split(\"r\")\n",
    "                if r_value not in r_values:\n",
    "                    r_values += [r_value]\n",
    "                if s_value not in s_values:\n",
    "                    s_values += [s_value]\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    num_r = len(r_values)\n",
    "    num_s = len(s_values)\n",
    "    if num_r > 0 and num_s > 0:\n",
    "        ## Convert to integers, and sort.\n",
    "        r_values = sorted([int(r) for r in r_values])\n",
    "        s_values = sorted([int(s) for s in s_values])\n",
    "    else:\n",
    "        print(\"No results found for '{}' dataset.\".format(dataset))\n",
    "        continue\n",
    "    \n",
    "    ## Initial prep of the figure.\n",
    "    fig, axes = plt.subplots(1, num_r, figsize=(12,3), sharex=True, sharey=True)\n",
    "    \n",
    "    ## Now we can just loop over the relevant files.\n",
    "    for i, r in enumerate(r_values):\n",
    "        \n",
    "        ## Relevant axis.\n",
    "        ax = axes[i] if num_r > 1 else axes\n",
    "        \n",
    "        ## Storage for values to be plotted.\n",
    "        x_values = []\n",
    "        y_values_dict = {etype: [] for etype in etypes}\n",
    "        \n",
    "        for s in s_values:\n",
    "            \n",
    "            task = \"s{}r{}\".format(s, r)\n",
    "            mth = \"-\".join([task, mth_base])\n",
    "            \n",
    "            ## Gather relevant information from the experiment JSON file.\n",
    "            with open(os.path.join(toread_dir, \".\".join([mth, \"json\"])), \"r\", encoding=\"utf-8\") as f:\n",
    "                json_dict = json_load(f)\n",
    "                num_trials = json_dict[\"num_trials\"]\n",
    "                x_values += [json_dict[\"step_size\"]]\n",
    "                \n",
    "                if s == 0:\n",
    "                    ## Get risk function parameters at first inner step.\n",
    "                    print(json_dict)\n",
    "                    extras = {key: json_dict[key] for key in extras_keys[riskclass]}\n",
    "                else:\n",
    "                    ## After that, make sure they all match.\n",
    "                    if not all([extras[key] == json_dict[key] for key in extras_keys[riskclass]]):\n",
    "                        raise ValueError(\"Extras don't match.\")\n",
    "            \n",
    "            ## Initialize a list for this specific risk setting.\n",
    "            results = {etype: [] for etype in etypes}\n",
    "            \n",
    "            ## Gather the results of interest.\n",
    "            for etype in results:\n",
    "                for trial in range(num_trials):\n",
    "                    ## Read in the results, add to a list that will be stacked soon.\n",
    "                    fname = mth+\"-\"+str(trial)+\".\"+ltype+\"_\"+etype\n",
    "                    with open(os.path.join(toread_dir, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                        values = np.loadtxt(fname=f, dtype=float, delimiter=\",\", ndmin=2)\n",
    "                        ## Add results for the current trial.\n",
    "                        results[etype] += [np.expand_dims(a=values, axis=0)]\n",
    "                \n",
    "                ## Having covered all trials, stack and process the arrays.\n",
    "                y_values_dict[etype] += [ np.vstack(results[etype]).mean(axis=0)[epoch_touse,stat_idx] ]\n",
    "                \n",
    "            \n",
    "        ## Plot these results.\n",
    "        x_values = np.array(x_values)\n",
    "        for etype in results:\n",
    "            y_values = np.array(y_values_dict[etype])\n",
    "            ax.semilogx(x_values, y_values, base=10, marker=\"o\",\n",
    "                        color=\"xkcd:black\", ls=linestyles[etype])\n",
    "        ax.tick_params(labelsize=my_fontsize)\n",
    "        ax.set_title(parse_extras(extras=extras, risk_name=riskclass), size=my_fontsize)\n",
    "        \n",
    "        ## Store the best task (based on validation data).\n",
    "        try:\n",
    "            best_settings[riskclass] += [\"s{}r{}\".format(np.nanargmin(y_values_dict[\"val\"]), r)]\n",
    "        except ValueError:\n",
    "            best_settings[riskclass] += [None]\n",
    "    \n",
    "        \n",
    "    ## Title and horizontal axis label for the figure.\n",
    "    fig.supxlabel(r\"Step size factor ($\\log_{10}$ scale)\", size=my_fontsize)\n",
    "    fig.suptitle(\"Empirical {} mean values (dataset: {})\".format(riskclass, dataset), size=my_fontsize)\n",
    "    \n",
    "    ## Display the figure.\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6bca1",
   "metadata": {},
   "source": [
    "Next, we visualize the trajectory (over time) of several key evaluation metrics of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the risks for which we want to visualize trajectories.\n",
    "riskclasses_tovis = [\"erm\", \"mvHuber\", \"cvar\", \"dro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea5c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the evaluation metrics to look at (from [\"base\", \"obj\", \"zeroone\", \"confuse\", \"l1\", \"l2\"]).\n",
    "ltypes = [\"base\", \"zeroone\", \"confuse\"]\n",
    "ltype_tovis = \"base\"\n",
    "etype = \"test\" # either \"train\", \"val\", or \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare a dictionary for storing results.\n",
    "results_allrisks = {}\n",
    "json_dicts_allrisks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17fac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Gathering of results (for trajectories).\n",
    "\n",
    "for riskclass in riskclasses_tovis:\n",
    "    \n",
    "    ## Initialize a list of results for each risk class.\n",
    "    results_list = []\n",
    "    json_dicts = []\n",
    "    \n",
    "    ## Grab the representative results.\n",
    "    for task in best_settings[riskclass]:\n",
    "        \n",
    "        if task is None:\n",
    "            print(\"Risk {}: task is none here; skipping.\".format(riskclass))\n",
    "            continue\n",
    "        \n",
    "        ## Identify the method for which we will gather results.\n",
    "        mth = task+\"-\"+riskclass+\"_\"+loss_base+\"_\"+model+\"_\"+algo\n",
    "        \n",
    "        ## Gather relevant information from the experiment JSON file.\n",
    "        with open(os.path.join(toread_dir, \".\".join([mth, \"json\"])), \"r\", encoding=\"utf-8\") as f:\n",
    "            json_dict = json_load(f)\n",
    "            num_trials = json_dict[\"num_trials\"]\n",
    "            \n",
    "        ## Initialize a dictionary for this specific risk setting.\n",
    "        results = {ltype: [] for ltype in ltypes}\n",
    "        \n",
    "        ## Gather the results of interest.\n",
    "        for ltype in ltypes:\n",
    "            for trial in range(num_trials):\n",
    "                ## Read in the results, add to a list that will be stacked soon.\n",
    "                fname = mth+\"-\"+str(trial)+\".\"+ltype+\"_\"+etype\n",
    "                with open(os.path.join(toread_dir, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                    values = np.loadtxt(fname=f, dtype=float, delimiter=\",\", ndmin=2)\n",
    "                    shape = values.shape\n",
    "                ## Add results for the current trial.\n",
    "                results[ltype] += [np.expand_dims(a=values, axis=0)]\n",
    "            \n",
    "            ## Having covered all trials, stack the arrays.\n",
    "            results[ltype] = np.vstack(results[ltype])\n",
    "        \n",
    "        ## Store results for this risk setting.\n",
    "        results_list += [deepcopy(results)]\n",
    "        json_dicts += [deepcopy(json_dict)]\n",
    "    \n",
    "    ## Finally, store the results dictionary for the current risk class.\n",
    "    results_allrisks[riskclass] = deepcopy(results_list)\n",
    "    json_dicts_allrisks[riskclass] = deepcopy(json_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d596bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the trajectories.\n",
    "\n",
    "figsize = (12,3.5) # nice size for paper.\n",
    "#figsize = (20,8) # nice size for viewing here.\n",
    "\n",
    "fig, axes = plt.subplots(1, len(riskclasses_tovis), figsize=figsize, sharey=True)\n",
    "\n",
    "## Loop over risk classes.\n",
    "for j, riskclass in enumerate(riskclasses_tovis):\n",
    "        \n",
    "    ## Result lists for this risk class.\n",
    "    results_list = results_allrisks[riskclass]\n",
    "    json_dicts = json_dicts_allrisks[riskclass]\n",
    "\n",
    "    ## Relevant bits of information.\n",
    "    num_risks = len(results_list)\n",
    "    \n",
    "    ## Color setup.\n",
    "    cmap = cm.get_cmap(\"plasma\")\n",
    "    colours = [cmap(k/num_risks) for k in range(num_risks)]\n",
    "    \n",
    "    ## Loop over the individual risks.\n",
    "    for k in range(num_risks):\n",
    "        \n",
    "        if riskclass == \"mvHuber\" and k > 0:\n",
    "            print(\"Only using strategy 0 for mvHuber.\")\n",
    "            continue\n",
    "        \n",
    "        ## Actual results of interest for plotting.\n",
    "        results = results_list[k]\n",
    "        json_dict = json_dicts[k]\n",
    "        \n",
    "        ## More relevant bits of information.\n",
    "        num_epochs = json_dict[\"num_epochs\"]\n",
    "        \n",
    "        ## Values to be plotted.\n",
    "        x_values = np.arange(num_epochs+1)\n",
    "        y_values = results[ltype_tovis][...,np.array([0,2])].sum(axis=2).mean(axis=0)\n",
    "        y_err = results[ltype_tovis][...,np.array([0,2])].sum(axis=2).std(axis=0)\n",
    "        \n",
    "        ## Plot results.\n",
    "        axes[j].plot(x_values, y_values, color=colours[k])\n",
    "        axes[j].fill_between(x=x_values, y1=y_values-y_err, y2=y_values+y_err,\n",
    "                                alpha=0.15, color=colours[k], lw=0)\n",
    "    \n",
    "    ## Column titles.\n",
    "    axes[j].set_title(risk_names[riskclass], size=my_fontsize)\n",
    "    axes[j].tick_params(labelsize=my_fontsize)\n",
    "\n",
    "## Title for the figure.\n",
    "fig_title = \"Mean + SD (dataset: {})\".format(dataset)\n",
    "fig.suptitle(fig_title, size=my_fontsize, fontweight=\"bold\")\n",
    "fname = os.path.join(img_dir, \"real_traj_mstd_{}.{}\".format(dataset, my_ext))\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7a5c8",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
